import time
import os
import hashlib
import hmac
import base64
import json
from .base import BaseCrawler

class SchoolCrawler(BaseCrawler):
    
    def __init__(self):
        super().__init__()
        self._first_school_logged = False
        self._api_fields_logged = False
    
    def generate_signsafe(self, params):
        """ç”Ÿæˆsignsafeç­¾å"""
        secret = "D23ABC@#56"
        sorted_keys = sorted(params.keys())
        query_string = '&'.join([f"{k}={params[k]}" for k in sorted_keys])
        sign_string = f"api-gaokao.zjzw.cn/apidata/web?{query_string}"
        
        hmac_result = hmac.new(
            secret.encode('utf-8'),
            sign_string.encode('utf-8'),
            hashlib.sha1
        ).digest()
        
        base64_result = base64.b64encode(hmac_result).decode('utf-8')
        final_signature = hashlib.md5(base64_result.encode('utf-8')).hexdigest()
        
        return final_signature
    
    def get_school_complete_info(self, school_id, is_first=False):
        """è·å–å­¦æ ¡å®Œæ•´ä¿¡æ¯ï¼ˆåŒ…å«ä»‹ç»ã€é‚®ç®±ç­‰æ‰€æœ‰æ•°æ®ï¼‰"""
        if is_first:
            print(f"\nğŸ“¡ [æ¥å£2-å®Œæ•´ä¿¡æ¯] school_id={school_id} (é¦–æ¬¡è°ƒç”¨ï¼Œæ˜¾ç¤ºå®Œæ•´å­—æ®µ)")
        else:
            print(f"\nğŸ“¡ [æ¥å£2-å®Œæ•´ä¿¡æ¯] school_id={school_id}")
        
        url = f"https://static-data.gaokao.cn/www/2.0/school/{school_id}/info.json"
        print(f"   è¯·æ±‚: {url}")
        
        try:
            response = self.session.get(url, timeout=10)
            print(f"   çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                code = result.get('code')
                print(f"   ä¸šåŠ¡ç : {code}")
                
                if code == '0000' and 'data' in result:
                    data = result['data']
                    
                    if isinstance(data, dict):
                        fields = list(data.keys())
                        print(f"   âœ“ è¿”å›å­—æ®µ({len(fields)}ä¸ª)")
                        
                        # é¦–æ¬¡è°ƒç”¨æ˜¾ç¤ºæ‰€æœ‰å­—æ®µ
                        if is_first:
                            print(f"\n   {'â”€'*55}")
                            print(f"   å®Œæ•´å­—æ®µåˆ—è¡¨:")
                            print(f"   {'â”€'*55}")
                            for i, field in enumerate(fields, 1):
                                value = data[field]
                                value_type = type(value).__name__
                                # æ˜¾ç¤ºå€¼çš„é¢„è§ˆ
                                if value is None:
                                    preview = "None"
                                elif isinstance(value, str):
                                    preview = f'"{value[:30]}..."' if len(value) > 30 else f'"{value}"'
                                elif isinstance(value, (list, dict)):
                                    preview = f"{value_type}({len(value)}é¡¹)"
                                else:
                                    preview = str(value)
                                print(f"   {i:3}. {field:30} = {preview}")
                            print(f"   {'â”€'*55}\n")
                        
                        # æ£€æŸ¥å…³é”®å­—æ®µ
                        has_content = 'content' in data
                        has_email = 'email' in data or 'emails' in data
                        has_site = 'site' in data or 'school_site' in data
                        
                        print(f"   >>> content: {'âœ“' if has_content else 'âœ—'}")
                        print(f"   >>> email: {'âœ“' if has_email else 'âœ—'}")
                        print(f"   >>> site: {'âœ“' if has_site else 'âœ—'}")
                        
                        if has_content and not is_first:
                            content_preview = data['content'][:80] if data['content'] else "ç©º"
                            print(f"   >>> å†…å®¹é¢„è§ˆ: {content_preview}...")
                        
                        return data
                    else:
                        print(f"   âš ï¸  dataç±»å‹å¼‚å¸¸: {type(data)}")
                else:
                    print(f"   âœ— é”™è¯¯: code={code}, message={result.get('message')}")
            else:
                print(f"   âœ— HTTPé”™è¯¯: {response.status_code}")
                
        except Exception as e:
            print(f"   âœ— å¼‚å¸¸: {str(e)}")
        
        return None

    def get_enhanced_school_list(self, page=1, size=20):
        """è·å–å¢å¼ºç‰ˆå­¦æ ¡åˆ—è¡¨"""
        if page == 1:
            print(f"\nğŸ“¡ [æ¥å£3-å¢å¼ºåˆ—è¡¨] page={page}, size={size}")
        
        base_url = "https://api-gaokao.zjzw.cn/apidata/web"
        cookie = os.getenv('GAOKAO_COOKIE', '')
        
        params = {
            "autosign": "",
            "keyword": "",
            "local_type_id": "2073",
            "page": str(page),
            "platform": "2",
            "province_id": "",
            "ranktype": "",
            "request_type": "1",
            "size": str(size),
            "spe_ids": "",
            "top_school_id": "",
            "uri": "v1/school/lists"
        }
        
        signsafe = self.generate_signsafe(params)
        query_string = '&'.join([f"{k}={params[k]}" for k in sorted(params.keys())])
        full_url = f"{base_url}?{query_string}&signsafe={signsafe}"
        
        post_body = {
            "autosign": "",
            "keyword": "",
            "local_type_id": 2073,
            "page": int(page),
            "platform": "2",
            "province_id": "",
            "ranktype": "",
            "request_type": 1,
            "signsafe": signsafe,
            "size": int(size),
            "spe_ids": "",
            "top_school_id": "",
            "uri": "v1/school/lists"
        }
        
        headers = self.headers.copy()
        if cookie:
            headers["cookie"] = cookie
            if page == 1:
                print(f"   ä½¿ç”¨Cookie: {cookie[:30]}...")
        else:
            if page == 1:
                print(f"   æœªé…ç½®Cookie")
        
        try:
            response = self.session.post(
                full_url,
                headers=headers,
                data=json.dumps(post_body),
                timeout=15
            )
            
            if page == 1:
                print(f"   çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                code = result.get('code')
                
                if page == 1:
                    print(f"   ä¸šåŠ¡ç : {code}")
                
                if code == 0:
                    items = result.get('data', {}).get('item', [])
                    if page == 1:
                        print(f"   âœ“ ç¬¬{page}é¡µè·å– {len(items)} æ‰€å­¦æ ¡")
                        
                        # æ˜¾ç¤ºå¢å¼ºæ•°æ®çš„å­—æ®µ
                        if items:
                            sample = items[0]
                            fields = list(sample.keys())
                            print(f"\n   å¢å¼ºæ•°æ®å­—æ®µ({len(fields)}ä¸ª):")
                            print(f"   {', '.join(fields)}")
                            print()
                    return result
                elif code == 1010001:
                    if page == 1:
                        print(f"   âœ— éœ€è¦Cookieè®¤è¯")
                else:
                    if page == 1:
                        print(f"   âœ— é”™è¯¯: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
            
        except Exception as e:
            if page == 1:
                print(f"   âœ— å¼‚å¸¸: {str(e)}")
        
        return None
    
    def merge_enhanced_data(self, schools_basic, max_pages=10):
        """å°†å¢å¼ºæ•°æ®åˆå¹¶åˆ°åŸºç¡€å­¦æ ¡åˆ—è¡¨"""
        enhanced_dict = {}
        
        print(f"\n{'='*60}")
        print(f"å¼€å§‹è·å–å¢å¼ºç‰ˆå­¦æ ¡æ•°æ®ï¼ˆæœ€å¤š{max_pages}é¡µï¼‰")
        print(f"{'='*60}")
        
        page = 1
        total_fetched = 0
        
        while page <= max_pages:
            enhanced_data = self.get_enhanced_school_list(page=page, size=20)
            
            if enhanced_data and enhanced_data.get('code') == 0:
                items = enhanced_data.get('data', {}).get('item', [])
                
                if not items:
                    print(f"   ç¬¬ {page} é¡µæ— æ•°æ®ï¼Œåœæ­¢")
                    break
                
                for item in items:
                    school_id = item.get('school_id')
                    if school_id:
                        enhanced_dict[school_id] = {
                            'label_list': item.get('label_list', []),
                            'recommend_master_level': item.get('recommend_master_level'),
                            'is_top': item.get('is_top'),
                            'attr_list': item.get('attr_list', []),
                            'hightitle': item.get('hightitle')
                        }
                        total_fetched += 1
                
                if page > 1:
                    print(f"   âœ“ ç¬¬{page}é¡µè·å– {len(items)} æ‰€å­¦æ ¡ï¼ˆç´¯è®¡{total_fetched}æ‰€ï¼‰")
                
                page += 1
                self.polite_sleep(3.0, 6.0)
            else:
                if page == 1 and not os.getenv('GAOKAO_COOKIE'):
                    print(f"\nğŸ’¡ æç¤ºï¼šå¢å¼ºæ•°æ®éœ€è¦Cookie")
                    print(f"   1. è®¿é—® www.gaokao.cn å¹¶ç™»å½•")
                    print(f"   2. F12 æ§åˆ¶å°è¾“å…¥: document.cookie")
                    print(f"   3. è®¾ç½® GitHub Secret: GAOKAO_COOKIE\n")
                break
        
        # åˆå¹¶æ•°æ®
        merged_count = 0
        for school in schools_basic:
            school_id = school.get('school_id')
            if school_id and school_id in enhanced_dict:
                school.update(enhanced_dict[school_id])
                merged_count += 1
        
        print(f"\nâœ“ æˆåŠŸåˆå¹¶ {merged_count}/{len(schools_basic)} æ‰€å­¦æ ¡çš„å¢å¼ºæ•°æ®")
        
        return schools_basic
    
    def crawl(self, max_pages=None, fetch_complete_info=True, fetch_enhanced=True):
        """çˆ¬å–å­¦æ ¡åˆ—è¡¨"""
        max_pages = max_pages or int(os.getenv('MAX_PAGES', '10'))
        fetch_complete_info = os.getenv('FETCH_COMPLETE_INFO', str(fetch_complete_info)).lower() == 'true'
        fetch_enhanced = os.getenv('FETCH_ENHANCED', str(fetch_enhanced)).lower() == 'true'
        
        schools = []
        print(f"\n{'='*60}")
        print(f"å¼€å§‹çˆ¬å–å­¦æ ¡åˆ—è¡¨ï¼ˆæœ€å¤š {max_pages} é¡µï¼‰")
        print(f"å®Œæ•´ä¿¡æ¯: {'âœ“' if fetch_complete_info else 'âœ—'} | "
              f"å¢å¼ºæ•°æ®: {'âœ“' if fetch_enhanced else 'âœ—'}")
        print(f"{'='*60}")
        
        for page in range(1, max_pages + 1):
            print(f"\nğŸ“¡ [æ¥å£1-åŸºç¡€åˆ—è¡¨] page={page}, size=20")
            
            payload = {
                "keyword": "",
                "page": page,
                "province_id": "",
                "ranktype": "",
                "request_type": 1,
                "size": 20,
                "type": "",
                "uri": "apidata/api/gkv3/school/lists"
            }
            
            data = self.make_request(payload)
            
            if not data or 'data' not in data or 'item' not in data['data']:
                print(f"   âœ— è¯·æ±‚å¤±è´¥")
                break
            
            items = data['data']['item']
            if not items:
                print(f"   âœ— æ— æ•°æ®ï¼Œåœæ­¢çˆ¬å–")
                break
            
            print(f"   âœ“ è·å– {len(items)} æ‰€å­¦æ ¡")
            
            # é¦–æ¬¡æ˜¾ç¤ºåŸºç¡€åˆ—è¡¨å­—æ®µ
            if page == 1 and items:
                sample_fields = list(items[0].keys())
                print(f"\n   åŸºç¡€åˆ—è¡¨å­—æ®µ({len(sample_fields)}ä¸ª):")
                print(f"   {', '.join(sample_fields)}")
            
            print(f"\n{'â”€'*60}")
            
            for idx, item in enumerate(items, 1):
                school_id = item.get('school_id')
                school_name = item.get('name')
                
                # ç¬¬ä¸€æ‰€å­¦æ ¡è¯¦ç»†æ˜¾ç¤ºï¼Œåç»­ç®€ç•¥
                is_first = (page == 1 and idx == 1)
                
                if is_first:
                    print(f"\n[{idx}/{len(items)}] {school_name} (ID:{school_id}) â­é¦–æ¬¡è¯¦ç»†æ˜¾ç¤º")
                else:
                    print(f"\n[{idx}/{len(items)}] {school_name} (ID:{school_id})")
                
                school_info = {
                    'school_id': school_id,
                    'name': school_name,
                    'province': item.get('province_name'),
                    'city': item.get('city_name'),
                    'county': item.get('county_name'),
                    'type': item.get('type_name'),
                    'level': item.get('level_name'),
                    'belong': item.get('belong'),
                    'rank': item.get('rank'),
                    'dual_class': item.get('dual_class_name'),
                    'f985': item.get('f985'),
                    'f211': item.get('f211'),
                    'is_dual_class': item.get('dual_class'),
                    'nature': item.get('nature_name'),
                    'view_total': item.get('view_total'),
                }
                
                # è·å–å®Œæ•´ä¿¡æ¯
                if fetch_complete_info and school_id:
                    complete_info = self.get_school_complete_info(school_id, is_first=is_first)
                    if complete_info:
                        # æå–æ‰€æœ‰å­—æ®µ
                        school_info.update({
                            'content': complete_info.get('content'),
                            'email': complete_info.get('email'),
                            'school_email': complete_info.get('school_email'),
                            'site': complete_info.get('site'),
                            'school_site': complete_info.get('school_site'),
                            'address': complete_info.get('address'),
                            'phone': complete_info.get('phone'),
                            'school_phone': complete_info.get('school_phone'),
                            'postcode': complete_info.get('postcode'),
                            'create_date': complete_info.get('create_date'),
                            'old_name': complete_info.get('old_name'),
                            'area': complete_info.get('area'),
                            'num_doctor': complete_info.get('num_doctor'),
                            'num_master': complete_info.get('num_master'),
                            'num_subject': complete_info.get('num_subject'),
                            'num_academician': complete_info.get('num_academician'),
                            'num_library': complete_info.get('num_library'),
                            'recommend_master_rate': complete_info.get('recommend_master_rate'),
                            'motto': complete_info.get('motto'),
                            'ruanke_rank': complete_info.get('ruanke_rank'),
                            'xyh_rank': complete_info.get('xyh_rank'),
                            'wsl_rank': complete_info.get('wsl_rank'),
                            'qs_rank': complete_info.get('qs_rank'),
                            'us_rank': complete_info.get('us_rank'),
                        })
                        
                        self.polite_sleep(2.0, 4.0)
                
                schools.append(school_info)
            
            print(f"\n{'â”€'*60}")
            print(f"âœ“ ç¬¬ {page} é¡µå®Œæˆ")
            self.polite_sleep(3.0, 6.0)
        
        # åˆå¹¶å¢å¼ºæ•°æ®
        if fetch_enhanced and schools:
            enhanced_pages = max(max_pages, (len(schools) // 20) + 2)
            schools = self.merge_enhanced_data(schools, max_pages=enhanced_pages)
        
        # åˆ†æå­—æ®µé‡å¤æƒ…å†µ
        if schools:
            print(f"\n{'='*60}")
            print(f"ğŸ“Š å­—æ®µåˆ†æ:")
            print(f"{'='*60}")
            
            first_school = schools[0]
            all_fields = list(first_school.keys())
            
            # æŒ‰æ¥æºåˆ†ç±»å­—æ®µ
            basic_fields = ['school_id', 'name', 'province', 'city', 'county', 'type', 
                           'level', 'belong', 'rank', 'dual_class', 'f985', 'f211', 
                           'is_dual_class', 'nature', 'view_total']
            
            enhanced_fields = ['label_list', 'recommend_master_level', 'is_top', 
                              'attr_list', 'hightitle']
            
            complete_fields = [f for f in all_fields if f not in basic_fields and f not in enhanced_fields]
            
            print(f"\næ¥æº1-åŸºç¡€åˆ—è¡¨ ({len(basic_fields)}ä¸ªå­—æ®µ):")
            print(f"  {', '.join(basic_fields)}")
            
            print(f"\næ¥æº2-å®Œæ•´ä¿¡æ¯ ({len(complete_fields)}ä¸ªå­—æ®µ):")
            print(f"  {', '.join(complete_fields)}")
            
            print(f"\næ¥æº3-å¢å¼ºæ•°æ® ({len(enhanced_fields)}ä¸ªå­—æ®µ):")
            print(f"  {', '.join(enhanced_fields)}")
            
            print(f"\næ€»è®¡: {len(all_fields)} ä¸ªå­—æ®µ")
            
            # æ£€æŸ¥é‡å¤å­—æ®µ
            print(f"\n{'â”€'*60}")
            print(f"é‡å¤å­—æ®µæ£€æŸ¥:")
            duplicates = []
            for field in basic_fields:
                if field in complete_fields:
                    duplicates.append(field)
            
            if duplicates:
                print(f"  âš ï¸  å‘ç° {len(duplicates)} ä¸ªé‡å¤å­—æ®µ: {', '.join(duplicates)}")
            else:
                print(f"  âœ“ æ— é‡å¤å­—æ®µ")
            
            # æ‰“å°ç¬¬ä¸€æ‰€å­¦æ ¡å®Œæ•´æ•°æ®
            print(f"\n{'='*60}")
            print(f"ğŸ“Š ç¬¬ä¸€æ‰€å­¦æ ¡å®Œæ•´æ•°æ® ({first_school['name']}):")
            print(f"{'='*60}")
            
            for key, value in first_school.items():
                if isinstance(value, str) and len(value) > 100:
                    print(f"  {key}: {value[:100]}...")
                elif isinstance(value, list):
                    print(f"  {key}: [åˆ—è¡¨,{len(value)}é¡¹] {value[:3] if len(value) <= 3 else f'{value[:2]}...'}")
                elif isinstance(value, dict):
                    print(f"  {key}: {{å­—å…¸,{len(value)}é¡¹}}")
                else:
                    print(f"  {key}: {value}")
            
            print(f"{'='*60}")
        
        self.save_to_json(schools, 'schools.json')
        print(f"\n{'='*60}")
        print(f"ğŸ‰ å­¦æ ¡çˆ¬å–å®Œæˆï¼å…± {len(schools)} æ‰€")
        print(f"{'='*60}\n")
        
        return schools

if __name__ == "__main__":
    import sys
    
    max_pages = int(sys.argv[1]) if len(sys.argv) > 1 else 1
    fetch_complete_info = sys.argv[2].lower() == 'true' if len(sys.argv) > 2 else True
    fetch_enhanced = sys.argv[3].lower() == 'true' if len(sys.argv) > 3 else True
    
    crawler = SchoolCrawler()
    crawler.crawl(
        max_pages=max_pages, 
        fetch_complete_info=fetch_complete_info,
        fetch_enhanced=fetch_enhanced
    )
